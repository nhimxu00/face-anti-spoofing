{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kywzGDIMbkT",
        "outputId": "0f906881-8ef6-4b21-aff8-fa189e0781ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'face-anti-spoofing'...\n",
            "remote: Enumerating objects: 929, done.\u001b[K\n",
            "remote: Counting objects: 100% (929/929), done.\u001b[K\n",
            "remote: Compressing objects: 100% (919/919), done.\u001b[K\n",
            "remote: Total 929 (delta 9), reused 929 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (929/929), 40.60 MiB | 19.27 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/nhimxu00/face-anti-spoofing.git\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/face-anti-spoofing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULDFHnDXMkKQ",
        "outputId": "a7be358d-554d-4b6d-cd49-b43e180e43b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/face-anti-spoofing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AphyhCXVMoub",
        "outputId": "516314de-2237-4b23-d509-10cb86437e48"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 22696\n",
            "drwxr-xr-x 3 root root     4096 Mar 21 03:43  config\n",
            "drwxr-xr-x 3 root root     4096 Mar 21 03:43  data\n",
            "drwxr-xr-x 3 root root     4096 Mar 21 03:43  datasets\n",
            "drwxr-xr-x 2 root root     4096 Mar 21 03:43  docs\n",
            "drwxr-xr-x 2 root root     4096 Mar 21 03:43  evaluation\n",
            "drwxr-xr-x 3 root root     4096 Mar 21 03:43  experiments\n",
            "-rw-r--r-- 1 root root 14497985 Mar 21 03:43  face.mp4\n",
            "drwxr-xr-x 2 root root     4096 Mar 21 03:43  inference\n",
            "drwxr-xr-x 3 root root     4096 Mar 21 03:43  models\n",
            "-rw-r--r-- 1 root root  1636772 Mar 21 03:43 'mtcnn face.jpg'\n",
            "-rw-r--r-- 1 root root       72 Mar 21 03:43  requirements.txt\n",
            "drwxr-xr-x 2 root root     4096 Mar 21 03:43  spliting_codes\n",
            "-rw-r--r-- 1 root root  1162139 Mar 21 03:43  test2.jpg\n",
            "-rw-r--r-- 1 root root  5885774 Mar 21 03:43  test2.png\n",
            "drwxr-xr-x 3 root root     4096 Mar 21 03:43  trainer\n",
            "-rw-r--r-- 1 root root     2889 Mar 21 03:43  train.py\n",
            "drwxr-xr-x 3 root root     4096 Mar 21 03:43  utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKewvz1eNDkm",
        "outputId": "633e4d20-ece5-42ae-d2f0-a57d06280d3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key='d65b790638e3fd6cf9f52a2ff3571e0e2b6a45ff')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HWhr-bQNHW9",
        "outputId": "2d37a100-671e-48f3-aa11-a13f05a1e757"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datasets.FASDataset import FASDataset\n",
        "from utils.transform import RandomGammaCorrection\n",
        "from utils.utils import read_cfg, get_optimizer, get_device, build_network\n",
        "from trainer.FASTrainer import FASTrainer\n",
        "from models.loss import DepthLoss\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "BQVzpyWzNYp7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = read_cfg(cfg_file=\"config/CDCNpp_adam_lr1e-3.yaml\")\n",
        "\n",
        "device = get_device(cfg)\n",
        "\n",
        "network = build_network(cfg)\n",
        "\n",
        "optimizer = get_optimizer(cfg, network)\n",
        "\n",
        "lr_scheduler = StepLR(optimizer=optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "criterion = DepthLoss(device=device)\n",
        "\n",
        "writer = SummaryWriter(cfg['log_dir'])\n",
        "\n",
        "dump_input = torch.randn((1, 3, cfg['model']['input_size'][0], cfg['model']['input_size'][1]))\n",
        "\n",
        "writer.add_graph(network, dump_input)"
      ],
      "metadata": {
        "id": "TQnEZ5njNcoL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project = \"TEST_1\",\n",
        "                 name = f\"Run_{datetime.now().strftime('%d%m%Y%H%M%S')}\", \n",
        "                 notes = \"increase learning rate\",\n",
        "                 tags = [],\n",
        "                 config = cfg,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "6zTfEkQqMwLv",
        "outputId": "9cbfa277-a39a-4ee8-baf7-beb24c06e5a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhxoanxu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/face-anti-spoofing/wandb/run-20230321_034415-zefigpag</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minhxoanxu/TEST_1/runs/zefigpag' target=\"_blank\">Run_21032023034415</a></strong> to <a href='https://wandb.ai/minhxoanxu/TEST_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/minhxoanxu/TEST_1' target=\"_blank\">https://wandb.ai/minhxoanxu/TEST_1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/minhxoanxu/TEST_1/runs/zefigpag' target=\"_blank\">https://wandb.ai/minhxoanxu/TEST_1/runs/zefigpag</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    RandomGammaCorrection(max_gamma=cfg['dataset']['augmentation']['gamma_correction'][1],\n",
        "                            min_gamma=cfg['dataset']['augmentation']['gamma_correction'][0]),\n",
        "    transforms.RandomResizedCrop(cfg['model']['input_size'][0]),\n",
        "    # transforms.ColorJitter(\n",
        "    #     brightness=cfg['dataset']['augmentation']['brightness'],\n",
        "    #     contrast=cfg['dataset']['augmentation']['contrast'],\n",
        "    #     saturation=cfg['dataset']['augmentation']['saturation'],\n",
        "    #     hue=cfg['dataset']['augmentation']['hue']\n",
        "    # ),\n",
        "    transforms.RandomRotation(cfg['dataset']['augmentation']['rotation_range']),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize(cfg['model']['input_size']),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cfg['dataset']['mean'], cfg['dataset']['sigma'])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(cfg['model']['input_size']),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cfg['dataset']['mean'], cfg['dataset']['sigma'])\n",
        "])\n",
        "\n",
        "trainset = FASDataset(\n",
        "    root_dir=cfg['dataset']['root'],\n",
        "    csv_file=cfg['dataset']['train_set'],\n",
        "    depth_map_size=cfg['model']['depth_map_size'],\n",
        "    transform=train_transform,\n",
        "    smoothing=cfg['train']['smoothing']\n",
        ")\n",
        "\n",
        "valset = FASDataset(\n",
        "    root_dir=cfg['dataset']['root'],\n",
        "    csv_file=cfg['dataset']['val_set'],\n",
        "    depth_map_size=cfg['model']['depth_map_size'],\n",
        "    transform=val_transform,\n",
        "    smoothing=cfg['train']['smoothing']\n",
        ")\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    dataset=trainset,\n",
        "    batch_size=cfg['train']['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(\n",
        "    dataset=valset,\n",
        "    batch_size=cfg['val']['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "CvpKHHSsNsPm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = FASTrainer(\n",
        "    cfg=cfg, \n",
        "    network=network,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    device=device,\n",
        "    trainloader=trainloader,\n",
        "    valloader=valloader,\n",
        "    writer=writer\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "NsoMA0D6MqFF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}